# Helm chart values for Production Deployment

# Production mode: disable Django Debug Mode (it can leak passwords/keys)
# Rather than toggling this value, reproduce your problem in the Development
# environment instead.
djangoDebug: false

# Django Secret Key
# This is overridden in eks-production1/prod/mop-values.yaml
djangoSecretKey: "overridden"

# Microlensing Observation Portal Secret Values
# These are overridden in eks-production1/prod/mop-values.yaml
antaresKey: ""
antaresPassword: ""
lcoApiKey: ""
lcoProposalId: ""
lcoUsername: ""

# AWS Credentials
# These are overridden in eks-production1/prod/mop-values.yaml
awsAccessKeyId: ""
awsSecretAccessKey: ""
awsS3Bucket: ""

# Production mode: run two replicas so that we can handle single machine
# outages (whether due to unplanned failure or planned maintenance)
replicaCount: 2

# Production mode: use production PostgreSQL database server
useDockerizedDatabase: false

# Apply database migrations when the application is started
applyDatabaseMigrations: true

# PostgreSQL server configuration is overridden in
# eks-production1/prod/mop-values.yaml
postgresql:
  hostname: "prod-postgres1-cluster-writer-pgbouncer.prod-db-proxy.svc.cluster.local"
  postgresqlDatabase: "mop"
  postgresqlUsername: "mop"
  postgresqlPassword: "overridden"

# MOP Container CPU/Memory Resource Requests/Limits
resources:
  requests:
    cpu: 500m
    memory: 768Mi
  limits:
    cpu: 4
    memory: 4Gi

# HTTP router configuration
ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx-ingress-public
    # Turn these on to disable all request buffering. In that case, you are on
    # your own in case of a DoS (Denial of Service) attack, or broken clients, or ..
    #nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    #nginx.ingress.kubernetes.io/proxy-body-size: "0"
  hosts:
    - host: mop.lco.global
      paths:
        - "/"

# CronJob: Fit Need Events
# ACTIVE
fitneedevents:
  enabled: false
  # Run in parallel across 6 Nodes (Machines) until all jobs are finished
  # Overruled: do not parallelize
  parallelism: 1
  # Use 3 CPU on each Node (Machine)
  cores: 3
  # CPU/Memory requests/limits
  resources:
    requests:
      cpu: 3000m
      memory: 2048Mi
    limits:
      cpu: 3500m
      memory: 4096Mi

# CronJob: Run TAP
# ACTIVE
runtap:
  enabled: false
  resources:
    requests:
      cpu: 10m
      memory: 2048Mi
    limits:
      cpu: 1000m
      memory: 4096Mi

# CronJob: Harvest ZTF DR3
# Logs into IPAC archive portal directly
# ACTIVE
harvestztfdr3:
  enabled: false
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1024Mi

# CronJob: Harvest GAIA
# ACTIVE
harvestgaia:
  enabled: false
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1024Mi

# CronJob: Harvest MOA
# ACTIVE
harvestmoa:
  enabled: false
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1024Mi

# CronJob: Harvest OGLE
# ACTIVE
harvestogle:
  enabled: false
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1024Mi

# CronJob: Add Gaia Classifier
# ACTIVE
gaiaclassifier:
  enabled: false
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1024Mi
